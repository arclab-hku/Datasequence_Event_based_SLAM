%YAML:1.0

#common parameters
imu_topic: "/davis_left/imu"
event0_topic: "/davis_left/events"
event1_topic: "/davis_right/events"
image0_topic: "/davis_left/image_raw"
image1_topic: "/davis_right/image_raw"
# image0_topic: "/record_new_image/left_image_raw"
# image1_topic: "/record_new_image/right_image_raw"

use_stereo: 1   #参数文件中默认为0
use_stereo_event: 1 #参数文件中默认为0

output_path: "/home/cpy/Datasets/output"

###########################################################################################################################

#camera calibration
cam0_calib: "cam0_esvio.yaml"
cam1_calib: "cam1_esvio.yaml"

#event calibration
event0_calib: "event0_esvio.yaml"
event1_calib: "event1_esvio.yaml"

model_type: PINHOLE
camera_name: camera
image_width: 346
image_height: 260
distortion_parameters:
   k1: -0.3794794654640921
   k2: 0.15393049046270296
   p1: 0.0011400586965363895
   p2: -0.0019042695753031854
projection_parameters:
   fx: 249.69341447817564
   fy: 248.41625664694038
   cx: 176.74240257052816
   cy: 129.47631010746218

event_width: 346
event_height: 260


###########################################################################################################################
# 下面是左相机跟IMU之间的关系

# Extrinsic parameter between IMU and Camera.
estimate_extrinsic: 1   # 0  Have an accurate extrinsic parameters. We will trust the following imu^R_cam, imu^T_cam, don't change it.
                        # 1  Have an initial guess about extrinsic parameters. We will optimize around your initial guess.
                        # 2  Don't know anything about extrinsic parameters. You don't need to give R,T. We will try to calibrate it. Do some rotation movement at beginning.
#If you choose 0 or 1, you should write down the following matrix.

#Rotation from camera frame to imu frame, imu^R_cam; 
extrinsicRotation: !!opencv-matrix 
   rows: 3
   cols: 3
   dt: d
   # data: [0.99995523,  0.00599467, -0.00732165,  
   #        -0.00603191,  0.99996893, -0.00507505,
   #        0.007291,    0.00511898,  0.99996032] 
   
   #### T_i2_i * T_i_c = [0,0,1;-1,0,0;0,-1,0]* T_i_c flight version####
   data: [0.00729100,0.00511899,0.99996032,  
          -0.99995523,-0.00599467,0.00732165,
          0.00603191,-0.99996893,0.00507505 ]
#Translation from camera frame to imu frame, imu^T_cam
extrinsicTranslation: !!opencv-matrix
   rows: 3
   cols: 1
   dt: d
   # data: [ -0.00054603,0.00046837, 0.06016175]

   #### T_i2_i * T_i_c = [0,0,1;-1,0,0;0,-1,0]* T_i_c flight version####
   data: [ -0.06016175,0.00054603, -0.00046837 ]

#### T_event_imu 左event和imu的关系
extrinsicRotation_event: !!opencv-matrix
   rows: 3
   cols: 3
   dt: d
   # data: [0.99995523,  0.00599467, -0.00732165,  
   #        -0.00603191,  0.99996893, -0.00507505,
   #        0.007291,    0.00511898,  0.99996032]
   
   #### T_i2_i * T_i_c = [0,0,1;-1,0,0;0,-1,0]* T_i_c flight version####
   data: [0.00729100,0.00511899,0.99996032,  
          -0.99995523,-0.00599467,0.00732165,
          0.00603191,-0.99996893,0.00507505 ]
extrinsicTranslation_event: !!opencv-matrix
   rows: 3
   cols: 1
   dt: d
   # data: [ -0.00054603,0.00046837, 0.06016175]

   #### T_i2_i * T_i_c = [0,0,1;-1,0,0;0,-1,0]* T_i_c flight version####
   data: [ -0.06016175,0.00054603, -0.00046837 ]

T_camera_imu: 0  # 是否输入的为imu到camera 。因为实际上程序里需要的为camera到imu，如果T_camera_imu =1 那么程序里会做一个转换。但一般矫正出来的都是imu到camera   if we set the R and T as IMU to camera, we need to give an T to them
T_event_imu: 0  # 是否输入的为imu到camera 。因为实际上程序里需要的为camera到imu，如果T_camera_imu =1 那么程序里会做一个转换。但一般矫正出来的都是imu到camera   if we set the R and T as IMU to camera, we need to give an T to them

###########################################################################################################################
# 下面是右相机跟左相机之间的关系（从左相机到右相机）
Rrl: !!opencv-matrix
   rows: 3
   cols: 3
   dt: d
   data: [ 0.9999189999842378, 0.00927392731970859, -0.00871709484799569,
          -0.009231577824269699, 0.9999454511978819, 0.004885959428529005, 
          0.008761931373541011, -0.004805091126247473, 0.9999500685823629] 

Trl: !!opencv-matrix
   rows: 3
   cols: 1
   dt: d
   data: [-0.05968052204060377 , -0.0005334476469976882, 0.0005990728587972945 ]

body_T_cam1: !!opencv-matrix # camera1 到IMU的变换, 右相機到imu
   rows: 4
   cols: 4
   dt: d
   data: [-0.00137886, 0.00993717, 0.99994968, -0.06083779,   
          -0.99999365, 0.00327260, -0.00141145, -0.05913152,   
          -0.00328646, -0.99994527, 0.00993259, -0.00120388,   
           0.00000000, 0.00000000, 0.00000000, 1.00000000 ]

###########################################################################################################################
# 下面是右event跟左event之间的关系（从左event到右event）
Rrl_event: !!opencv-matrix
   rows: 3
   cols: 3
   dt: d
   data: [ 0.9999189999842378, 0.00927392731970859, -0.00871709484799569,
          -0.009231577824269699, 0.9999454511978819, 0.004885959428529005, 
          0.008761931373541011, -0.004805091126247473, 0.9999500685823629] 

Trl_event: !!opencv-matrix
   rows: 3
   cols: 1
   dt: d
   data: [-0.05968052204060377 , -0.0005334476469976882, 0.0005990728587972945 ]

body_T_event1: !!opencv-matrix # event1 到IMU的变换, 右event到imu
   rows: 4
   cols: 4
   dt: d
   data: [-0.00137886, 0.00993717, 0.99994968, -0.06083779,   
          -0.99999365, 0.00327260, -0.00141145, -0.05913152,   
          -0.00328646, -0.99994527, 0.00993259, -0.00120388,   
           0.00000000, 0.00000000, 0.00000000, 1.00000000 ]

###########################################################################################################################
#time surface map
ignore_polarity: 0 #true 1 false 0;
decay_ms: 20 #20
median_blur_kernel_size: 0 #1 or 0
feature_filter_threshold: 0.01

#feature traker paprameters
TS_LK_threshold: 128.0   # the feature detection is based on the time surface
max_cnt: 150 #250 #300 #150            # max feature number in feature tracking event 
max_cnt_img: 150                       # max feature number in feature tracking image
min_dist: 10 #10            # min distance between two event features 
min_dist_img: 10            # min distance between two image features 
freq: 15 # ESVIO 15  ESIO 10             # frequence (Hz) of publish tracking result. At least 10Hz for good estimation. If set 0, the frequence will be same as raw image 
# freq_img: 15           #图像频率
F_threshold: 1.0        # ransac threshold (pixel)
show_track: 1           # publish tracking image as topic
flow_back: 1            # perform forward and backward optical flow to improve feature tracking accuracy
equalize: 0             # if image is too dark or light, trun on equalize to find enough features
fisheye: 0              # if using fisheye, trun on it. A circle mask will be loaded to remove edge noisy points
Num_of_thread: 4        #number of the threads for the big event data process

# line feature
MIN_length: 20 #5 #10
Scale_image: 0.5 #0.8 #0.1 #1.0   #The scale of the image that will be used to find the lines. Range (0..1].
Do_motion_correction: 1 #是否做event的运动补偿

###########################################################################################################################
#optimization parameters
max_solver_time: 0.04  # max solver itration time (ms), to guarantee real time
max_num_iterations: 8   # max solver itrations, to guarantee real time
keyframe_parallax: 10.0 # keyframe selection threshold (pixel)

###########################################################################################################################
#imu parameters       The more accurate parameters you provide, the better performance
# seems 0.12 & 0.02 is a better choice compared to 0.1 & 0.05
acc_n: 0.2 #4.4793336127290362e-02 #0.1 #0.2  #4.4793336127290362e-02        # accelerometer measurement noise standard deviation. #0.2   0.04
gyr_n: 0.05 #3.1404034561189407e-03 #0.025 #0.05 #3.1404034561189407e-03        # gyroscope measurement noise standard deviation.     #0.05  0.004
acc_w: 0.002 #8.0169405615955990e-04 #0.001 #0.002 #8.0169405615955990e-04        # accelerometer bias random work noise standard deviation.  #0.002
gyr_w: 4.0e-5 #2.8618210492185127e-05 #2.0e-5 #4.0e-5 #2.8618210492185127e-05       # gyroscope bias random work noise standard deviation.     #4.0e-5
g_norm: 9.80766     # gravity magnitude

###########################################################################################################################

#unsynchronization parameters
estimate_td: 1                      # online estimate time offset between camera and imu
td: 0.00777437    #0.0            # initial value of time offset. unit: s. readed image clock + td = real image clock (IMU clock)

#rolling shutter parameters
rolling_shutter: 0                  # 0: global shutter camera, 1: rolling shutter camera
rolling_shutter_tr: 0               # unit: s. rolling shutter read out time per frame (from data sheet).

###########################################################################################################################

#loop closure parameters
loop_closure: 1                    # start loop closure
# loop_closure_topic: "/stereo_event_tracker/timesurface_map"   #use the time surface for loop closure
# loop_closure_topic: "/stereo_event_tracker/event_loop"   #use the event_msg for loop closure
loop_closure_topic: "/davis_left/image_raw"   #采用image做回环 
load_previous_pose_graph: 0 #1        # load and reuse previous pose graph; load from 'pose_graph_save_path'
fast_relocalization: 0             # useful in real-time and large project
# pose_graph_save_path: "/home/kwanwaipang/evio_result_visualization/outdoor_round3/pose_graph/" # save and load path

#visualization parameters
save_image: 1                   #  (DEBUG_IMAGE)   save image in pose graph for visualization purpose; you can close this function by setting 0 
visualize_imu_forward: 1        # output imu forward propogation to achieve low latency and high frequence results
visualize_camera_size: 0.4      # size of camera marker in RVIZ
save_loop_match: 0              # 
